{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5b75f6",
   "metadata": {},
   "source": [
    "## Máster en Big Data y Data Science\n",
    "\n",
    "### Metodologías de gestión y diseño de proyectos de big data\n",
    "\n",
    "#### AP2 - Modelado y evaluación\n",
    "\n",
    "---\n",
    "\n",
    "En esta libreta se realiza la experimentación para generación del modelo de predicción objetivo del proyecto y la evaluación del mismo.\n",
    "La versión del dataset a utilizar es la obtenida a partir de las operaciones de transformación.\n",
    "\n",
    "---\n",
    "\n",
    "En esta versión de la libreta se va a incorporar el registro de los detalles de la experimentación con la librería MFLOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98487f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerías necesarias y se suprimen las advertencias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f42e5",
   "metadata": {},
   "source": [
    "Se agrega la librería mlflow y se configura inicialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eba3732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:d:/Formación/Master en Big Data y Ciencia de '\n",
       " 'Datos/Asignaturas/13_Metodologias de gestion y diseño proyectos Big '\n",
       " 'Data/Template '\n",
       " 'Original/Master_VIU_13MBID_Abr2526/notebooks/mlruns/211776156448520195'), creation_time=1762503407948, experiment_id='211776156448520195', last_update_time=1762503407948, lifecycle_stage='active', name='Proyecto 13MBID-Abr2526 - Experimentacion Original', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import datetime as datetime\n",
    "\n",
    "# Configuración de MLflow\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"Proyecto 13MBID-Abr2526 - Experimentacion Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60d8e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Teléfono</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Teléfono</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>Teléfono</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Teléfono</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Teléfono</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education housing loan   contact month  \\\n",
       "0   56  housemaid  married     basic.4y      no   no  Teléfono   may   \n",
       "1   57   services  married  high.school      no   no  Teléfono   may   \n",
       "2   37   services  married  high.school     yes   no  Teléfono   may   \n",
       "3   40     admin.  married     basic.6y      no   no  Teléfono   may   \n",
       "4   56   services  married  high.school      no  yes  Teléfono   may   \n",
       "\n",
       "  day_of_week  duration  campaign  pdays  previous     poutcome  emp_var_rate  \\\n",
       "0         mon       261         1    999         0  nonexistent           1.1   \n",
       "1         mon       149         1    999         0  nonexistent           1.1   \n",
       "2         mon       226         1    999         0  nonexistent           1.1   \n",
       "3         mon       151         1    999         0  nonexistent           1.1   \n",
       "4         mon       307         1    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          93.994          -36.4      4.857       5191.0  0  \n",
       "1          93.994          -36.4      4.857       5191.0  0  \n",
       "2          93.994          -36.4      4.857       5191.0  0  \n",
       "3          93.994          -36.4      4.857       5191.0  0  \n",
       "4          93.994          -36.4      4.857       5191.0  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de los datos\n",
    "df = pd.read_csv('../data/processed/bank_processed.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef1a6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide el dataset en variables predictoras y variable objetivo\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5be62f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera el conjunto de entrenamiento y prueba con estratificación\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f1ce41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate',\n",
       "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['job', 'marital', 'education', 'housing', 'loan', 'contact', 'month',\n",
       "       'day_of_week', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se separan las columnas numéricas\n",
    "numerical_columns=X_train.select_dtypes(exclude='object').columns\n",
    "display(numerical_columns)\n",
    "\n",
    "categorical_columns=X_train.select_dtypes(include='object').columns\n",
    "display(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9e4f9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    27179\n",
       "1     3406\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se verifica la distribución de la variable objetivo en el conjunto de entrenamiento\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8d895fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un pipeline para preprocesamiento de datos\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler  \n",
    "\n",
    "# Pipeline para valores numéricos\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para valores categóricos\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('OneHotEncoder', OneHotEncoder(drop='first',sparse_output=False))\n",
    "])\n",
    "\n",
    "# Se configuran los preprocesadores\n",
    "preprocessor_full = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, numerical_columns),\n",
    "    ('cat_pipeline', cat_pipeline, categorical_columns)\n",
    "]).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b1bb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_train_valid = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, numerical_columns),\n",
    "    ('cat_pipeline', cat_pipeline, categorical_columns)\n",
    "]).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47621435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ajusta y transforma el conjunto de entrenamiento y prueba\n",
    "x_train_prep = preprocessor_full.fit_transform(X_train)\n",
    "x_test_prep = preprocessor_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d46c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño original: 30585\n",
      "Tamaño balanceado: 5438\n",
      "Distribución balanceada: target\n",
      "0.0    2719\n",
      "1.0    2719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Se aplica submuestreo a los datos preprocesados\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Combinar los datos preprocesados con las etiquetas\n",
    "train_data = x_train_prep.copy()\n",
    "train_data['target'] = y_train.reset_index(drop=True)\n",
    "\n",
    "# Separar por clase\n",
    "class_0 = train_data[train_data['target'] == 0]\n",
    "class_1 = train_data[train_data['target'] == 1]\n",
    "\n",
    "# Encontrar la clase minoritaria\n",
    "min_count = min(len(class_0), len(class_1))\n",
    "\n",
    "# Submuestreo balanceado - tomar una muestra igual al tamaño de la clase minoritaria\n",
    "class_0_balanced = resample(class_0, n_samples=min_count, random_state=42)\n",
    "class_1_balanced = resample(class_1, n_samples=min_count, random_state=42)\n",
    "\n",
    "# Combinar las clases balanceadas\n",
    "balanced_data = pd.concat([class_0_balanced, class_1_balanced])\n",
    "\n",
    "# Separar características y objetivo\n",
    "x_train_resampled = balanced_data.drop('target', axis=1)\n",
    "y_train_resampled = balanced_data['target']\n",
    "\n",
    "print(f\"Tamaño original: {len(x_train_prep)}\")\n",
    "print(f\"Tamaño balanceado: {len(x_train_resampled)}\")\n",
    "print(f\"Distribución balanceada: {y_train_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667fafa7",
   "metadata": {},
   "source": [
    "--- \n",
    "Este apartado se va a cambiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Se genera una función para realizar validación cruzada\n",
    "def cross_val(model):\n",
    "    scores = cross_val_score(model,x_train_resampled , y_train_resampled, cv=5, scoring='f1')\n",
    "    print('cross validation f1 scores',scores*100)\n",
    "    print('cross validation f1 mean',scores.mean()*100)\n",
    "    print('cross validation f1 std',scores.std())\n",
    "    print('-'*50)\n",
    "    scores = cross_val_score(model,x_train_resampled , y_train_resampled, cv=5, scoring='recall')\n",
    "    print('cross validation recall scores',scores*100)\n",
    "    print('cross validation recall mean',scores.mean()*100)\n",
    "    print('cross validation recall std',scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85be845",
   "metadata": {},
   "source": [
    "---\n",
    "El cambio consiste en que la función directamente registre los detalles de la experimentación en mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6fb4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "def cross_val_mlflow(model, model_name, params=None):\n",
    "    \"\"\"\n",
    "    Realiza validación cruzada y registra los resultados en MLflow.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        f1_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='f1')\n",
    "        f1_mean = f1_scores.mean()\n",
    "        f1_std = f1_scores.std()\n",
    "\n",
    "        recall_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='recall')\n",
    "        recall_mean = recall_scores.mean()\n",
    "        recall_std = recall_scores.std()\n",
    "\n",
    "        precision_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='precision')\n",
    "        precision_mean = precision_scores.mean()\n",
    "        precision_std = precision_scores.std()\n",
    "\n",
    "        accuracy_scores = cross_val_score(model, x_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "        accuracy_mean = accuracy_scores.mean()\n",
    "        accuracy_std = accuracy_scores.std()\n",
    "        \n",
    "        # Entrenamos al modelo\n",
    "        model.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Hacemos predicciones\n",
    "        y_pred = model.predict(x_test_prep)\n",
    "\n",
    "        # Obtenemos model_signature\n",
    "        signature = infer_signature(x_train_resampled, y_pred)\n",
    "\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        test_recall = recall_score(y_test, y_pred)\n",
    "        test_precision = precision_score(y_test, y_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Registramos los parámetros y métricas en MLflow\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        else:\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "        mlflow.log_params({\n",
    "            \"train_samples\": len(x_train_resampled),\n",
    "            \"test_samples\": len(x_test_prep),\n",
    "            \"balancing_method\": \"undersampling\",\n",
    "            \"cv_folds\": 5\n",
    "        })\n",
    "\n",
    "        # Registramos las métricas de validación cruzada\n",
    "        mlflow.log_metrics({\n",
    "            \"cv_f1_mean\": f1_mean,\n",
    "            \"cv_f1_std\": f1_std,\n",
    "            \"cv_recall_mean\": recall_mean,\n",
    "            \"cv_recall_std\": recall_std,\n",
    "            \"cv_precision_mean\": precision_mean,\n",
    "            \"cv_precision_std\": precision_std,\n",
    "            \"cv_accuracy_mean\": accuracy_mean,\n",
    "            \"cv_accuracy_std\": accuracy_std,\n",
    "        })\n",
    "        \n",
    "        mlflow.log_metrics({  \n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_accuracy\": test_accuracy\n",
    "        })\n",
    "\n",
    "        # Registramos el modelo\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            name=\"model\",\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "        print(f\"Modelo {model_name} registrado en MLflow con ID de ejecución: {mlflow.active_run().info.run_id}\")\n",
    "\n",
    "        return model, {\n",
    "            \"cv_f1_mean\": f1_mean,\n",
    "            \"cv_recall_mean\": recall_mean,\n",
    "            \"cv_precision_mean\": precision_mean,\n",
    "            \"cv_accuracy_mean\": accuracy_mean,\n",
    "            \"cv_accuracy_std\": accuracy_std,\n",
    "            \"test_f1\": test_f1,\n",
    "            \"test_recall\": test_recall,\n",
    "            \"test_precision\": test_precision,\n",
    "            \"test_accuracy\": test_accuracy\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429a99a",
   "metadata": {},
   "source": [
    "---\n",
    "Se cambian estas celdas por una sola que hace todas las llamadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deca8c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m,solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000000001\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# cross validation scores\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mcross_val\u001b[49m(lr)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val' is not defined"
     ]
    }
   ],
   "source": [
    "# Se aplica un modelo de regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1,penalty='l2',solver='liblinear',random_state=1,max_iter=100,tol=0.000000001)\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(max_iter=10000,tol=0.001)\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knclassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier()\n",
    "\n",
    "# cross validation scores\n",
    "cross_val(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree plot\n",
    "from sklearn.tree import plot_tree\n",
    "tree.fit(x_train_prep, y_train)\n",
    "plot_tree(tree, filled=True, rounded=True,max_depth=2,fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene la matriz de confusión para el modelo\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = tree.predict(x_test_prep)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b60a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se visualiza la matriz de confusión\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['no', 'yes'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a500b0c",
   "metadata": {},
   "source": [
    "---\n",
    "Esta es la nueva celda que hace la invocación al proceso con mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06d81dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Logistic Regression registrado en MLflow con ID de ejecución: cd1d78e1554b44c3a9121ee8bf0c4697\n",
      "Modelo Linear SVC registrado en MLflow con ID de ejecución: 320688ccfaf949cb878c74deda281a22\n",
      "Modelo K-Nearest Neighbors registrado en MLflow con ID de ejecución: 007ac4a682ae4bb58f1a9be01b901213\n",
      "Modelo Decision Tree Classifier registrado en MLflow con ID de ejecución: 3e1d9fe537284db6848ca21b3de75b37\n",
      "Modelo Random Forest Classifier registrado en MLflow con ID de ejecución: 9a1b4601423e4a0089d21d0235e1ae0a\n",
      "Modelo Gaussian Naive Bayes registrado en MLflow con ID de ejecución: c68c5ca1d9a84a02838cb8671802924c\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.naive_bayes as nb\n",
    "\n",
    "# Resultados\n",
    "resultados = {}\n",
    "    \n",
    "# Método 1 - Regresión Logística\n",
    "lr = LogisticRegression(C=1,penalty='l2',solver='liblinear',random_state=17,max_iter=100,tol=0.000000001)\n",
    "model_lr, metrics_lr = cross_val_mlflow(lr, \"Logistic Regression\")\n",
    "resultados['Logistic Regression'] = metrics_lr\n",
    "\n",
    "# Método 2 - SVC\n",
    "svc = LinearSVC(max_iter=10000,tol=0.001, random_state=17)   \n",
    "model_svc, metrics_svc = cross_val_mlflow(svc, \"Linear SVC\")\n",
    "resultados['Linear SVC'] = metrics_svc\n",
    "# Método 3 - KNN\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "model_knc, metrics_knc = cross_val_mlflow(knc, \"K-Nearest Neighbors\")\n",
    "resultados['K-Nearest Neighbors'] = metrics_knc\n",
    "\n",
    "# Método 4 - Decision Tree\n",
    "tree = DecisionTreeClassifier(random_state=17)\n",
    "model_tree, metrics_tree = cross_val_mlflow(tree, \"Decision Tree Classifier\")\n",
    "resultados['Decision Tree Classifier'] = metrics_tree\n",
    "\n",
    "# Método 5 - Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=17)   \n",
    "model_rf, metrics_rf = cross_val_mlflow(rf, \"Random Forest Classifier\")\n",
    "resultados['Random Forest Classifier'] = metrics_rf\n",
    "\n",
    "# Método 6 - Naive Bayes\n",
    "gnb = nb.GaussianNB()\n",
    "model_gnb, metrics_gnb = cross_val_mlflow(gnb, \"Gaussian Naive Bayes\")\n",
    "resultados['Gaussian Naive Bayes'] = metrics_gnb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd452296",
   "metadata": {},
   "source": [
    "--- \n",
    "A continuación se realiza una comparación de los modelos para seleccionar el que va a ser utilizado posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aee9f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          cv_f1_mean  cv_recall_mean  cv_precision_mean  \\\n",
      "Decision Tree Classifier      0.6992          0.7437             0.6598   \n",
      "K-Nearest Neighbors           0.5699          0.5815             0.5591   \n",
      "Gaussian Naive Bayes          0.6578          0.9507             0.5029   \n",
      "Random Forest Classifier      0.6964          0.6925             0.7003   \n",
      "Logistic Regression           0.5244          0.5204             0.5289   \n",
      "Linear SVC                    0.5240          0.5204             0.5281   \n",
      "\n",
      "                          cv_accuracy_mean  cv_accuracy_std  test_f1  \\\n",
      "Decision Tree Classifier            0.6800           0.0100   0.1657   \n",
      "K-Nearest Neighbors                 0.5612           0.0137   0.1551   \n",
      "Gaussian Naive Bayes                0.5055           0.0070   0.1469   \n",
      "Random Forest Classifier            0.6980           0.0097   0.1224   \n",
      "Logistic Regression                 0.5278           0.0213   0.1100   \n",
      "Linear SVC                          0.5270           0.0193   0.1087   \n",
      "\n",
      "                          test_recall  test_precision  test_accuracy  \n",
      "Decision Tree Classifier       0.3796          0.1060         0.5746  \n",
      "K-Nearest Neighbors            0.3960          0.0965         0.5199  \n",
      "Gaussian Naive Bayes           0.6663          0.0825         0.1386  \n",
      "Random Forest Classifier       0.2186          0.0850         0.6512  \n",
      "Logistic Regression            0.2656          0.0693         0.5216  \n",
      "Linear SVC                     0.2585          0.0688         0.5283  \n",
      "\n",
      "El mejor modelo basado en F1 en el conjunto de pruebas es: Decision Tree Classifier\n",
      "Valor de F1 en test: 0.1657\n",
      "Valor de Recall en test: 0.3796\n"
     ]
    }
   ],
   "source": [
    "df_comparacion = pd.DataFrame(resultados).T\n",
    "df_comparacion = df_comparacion.round(4)\n",
    "df_comparacion = df_comparacion.sort_values(by='test_f1', ascending=False)\n",
    "\n",
    "print(df_comparacion)\n",
    "\n",
    "print(\"\\nEl mejor modelo basado en F1 en el conjunto de pruebas es:\", df_comparacion.index[0])\n",
    "print(\"Valor de F1 en test:\", df_comparacion.iloc[0]['test_f1'])\n",
    "print(\"Valor de Recall en test:\", df_comparacion.iloc[0]['test_recall'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bdc3a",
   "metadata": {},
   "source": [
    "#### Predicción con datos nuevos (sin clasificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nuevos = pd.read_csv('../data/raw/bank-additional-new.csv')\n",
    "df_nuevos.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6746b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosticar el problema con los nuevos datos\n",
    "print(\"Información del conjunto de datos nuevos:\")\n",
    "print(f\"Forma: {df_nuevos.shape}\")\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(df_nuevos.dtypes)\n",
    "print(\"\\nValores nulos:\")\n",
    "print(df_nuevos.isnull().sum())\n",
    "print(\"\\nColumnas categóricas en nuevos datos:\")\n",
    "print(df_nuevos.select_dtypes(include='object').columns.tolist())\n",
    "print(\"\\nColumnas numéricas en nuevos datos:\")\n",
    "print(df_nuevos.select_dtypes(exclude='object').columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6597f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar con los datos de entrenamiento originales\n",
    "print(\"Comparación de columnas:\")\n",
    "print(f\"Columnas en datos originales: {list(X.columns)}\")\n",
    "print(f\"Columnas en datos nuevos: {list(df_nuevos.columns)}\")\n",
    "\n",
    "print(\"\\nColumnas que están en nuevos pero no en originales:\")\n",
    "new_cols = set(df_nuevos.columns) - set(X.columns)\n",
    "print(new_cols)\n",
    "\n",
    "print(\"\\nColumnas que están en originales pero no en nuevos:\")\n",
    "missing_cols = set(X.columns) - set(df_nuevos.columns)\n",
    "print(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace la predicción con los nuevos datos\n",
    "# Primero, eliminar la columna objetivo si existe y preparar las características\n",
    "X_new = df_nuevos.drop('y', axis=1) if 'y' in df_nuevos.columns else df_nuevos.copy()\n",
    "\n",
    "# Asegurar que las columnas estén en el mismo orden que en el entrenamiento\n",
    "X_new = X_new[X.columns]\n",
    "\n",
    "# Manejar la columna contacted_before para que coincida con el formato de entrenamiento\n",
    "# En entrenamiento: 'no', 'yes' (string)\n",
    "# En nuevos datos: NaN -> necesita convertirse a 'no' (asumiendo que NaN significa no contactado)\n",
    "X_new['contacted_before'] = X_new['contacted_before'].fillna('no')\n",
    "\n",
    "# Convertir cualquier valor numérico a string si es necesario\n",
    "if X_new['contacted_before'].dtype in ['float64', 'int64']:\n",
    "    X_new['contacted_before'] = X_new['contacted_before'].map({0.0: 'no', 1.0: 'yes'}).fillna('no')\n",
    "\n",
    "# Asegurar que contacted_before sea de tipo object como en entrenamiento\n",
    "X_new['contacted_before'] = X_new['contacted_before'].astype('object')\n",
    "\n",
    "# Transformar los nuevos datos usando el mismo preprocesador y predecir\n",
    "try:\n",
    "    x_new_prep = preprocessor_full.transform(X_new)\n",
    "    \n",
    "    y_new_pred = tree.predict(x_new_prep)\n",
    "    print(f\"\\nPredicciones: {y_new_pred}\")\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Cliente': range(1, len(y_new_pred) + 1),\n",
    "        'Predicción_Numérica': y_new_pred,\n",
    "        'Suscribirá': ['No' if pred == 0 else 'Sí' for pred in y_new_pred]\n",
    "    })\n",
    "    print(\"\\nResultados detallados:\")\n",
    "    print(predictions_df.to_string(index=False))\n",
    "    \n",
    "    # Resumen de predicciones\n",
    "    pred_counts = pd.Series(y_new_pred).value_counts()\n",
    "    print(\"\\nResumen de predicciones:\")\n",
    "    for pred_val, count in pred_counts.items():\n",
    "        label = 'No realizará un depósito' if pred_val == 0 else 'Sí realizará un depósito'\n",
    "        print(f\"  {label}: {count} clientes ({count/len(y_new_pred)*100:.1f}%)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error durante el preprocesamiento o predicción: {e}\")\n",
    "    print(\"Información adicional para depuración:\")\n",
    "    print(f\"Tipos de datos en X_new:\\n{X_new.dtypes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
